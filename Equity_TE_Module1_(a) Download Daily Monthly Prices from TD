# -*- coding: utf-8 -*-
"""
===============================================================================
EQUITY TE ATTRIBUTION — MODULE 1: DATA ACQUISITION (v2 — Dual API)
===============================================================================

Dynamically reads tickers from a Portfolio Holdings Excel file, downloads
all data required for multi-factor tracking error attribution, and saves
to a single Excel workbook for Module 2 consumption.

Data sources:
  - Twelve Data API:  monthly prices, daily prices (low credit cost)
  - FMP (Financial Modeling Prep) API:  fundamentals — FREE (250 calls/day)
      profile (market cap, beta), income statement, balance sheet
  - Kenneth French Data Library:  FF5 + Momentum factor returns (local files)
  - Twelve Data API:  SPLV & SPY prices for low-volatility factor

API budget for 23 securities:
  Twelve Data:  ~50 calls (prices only, 1 credit each)
  FMP:          ~69 calls (3 per ticker, free plan allows 250/day)

Output Excel sheets:
  1. Config              — reference date, parameters, run metadata
  2. Portfolio_Weights    — ticker + weight from Holdings sheet
  3. Benchmark_Weights    — ticker + weight from Equity benchmark sheet
  4. Monthly_Prices       — 85 months of month-end close prices per ticker
  5. Daily_Prices         — trailing ~70 trading days of close prices per ticker
  6. Fundamentals         — market cap, book value, beta, profitability, assets
  7. Factor_Returns       — Mkt-RF, SMB, HML, RMW, CMA, Mom, Vol (monthly)
  8. Data_Log             — per-ticker data availability and errors

Required packages: pandas, numpy, requests, openpyxl

Author: TEV Attribution Project
Date: February 2026
===============================================================================
"""

import pandas as pd
import numpy as np
import requests
import time
import traceback
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION — UPDATE THESE BEFORE RUNNING
# =============================================================================

# --- API Keys ---
# Twelve Data (for prices): https://twelvedata.com — free plan = 8 calls/min
TWELVE_DATA_API_KEY = "API key"

# Financial Modeling Prep (for fundamentals): https://financialmodelingprep.com
# Free plan = 250 calls/day. Get key at: https://site.financialmodelingprep.com/developer
FMP_API_KEY = "API key"

# --- Portfolio Holdings File ---
HOLDINGS_FILE = (Portfolio holdings.xlsx")

PORTFOLIO_SHEET = "Holdings"
BENCHMARK_SHEET = "Equity benchmark"
TICKER_COLUMN = "Ticker"
WEIGHT_COLUMN = "Weight"

# --- Fama-French Factor Files (local) ---
# FF5: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_CSV.zip
# Mom: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Momentum_Factor_CSV.zip
FF5_FILE = (Fama French Factor returns\F-F_Research_Data_5_Factors_2x3_CSV (1)\F-F_Research_Data_5_Factors_2x3.csv")

MOMENTUM_FILE = ""  # Leave empty if Mom is already in FF5_FILE

# --- Output ---
OUTPUT_FILE = "Equity_TE_Data.xlsx"

# --- Reference Date and Lookback ---
REFERENCE_DATE = "2026-02-06"
MONTHLY_LOOKBACK_MONTHS = 85        # 80 for covariance + buffer
DAILY_LOOKBACK_CALENDAR_DAYS = 100  # ~63 trading days + buffer

# --- Rate Limiting ---
TD_CALLS_PER_MINUTE = 8    # Twelve Data free plan = 8/min
FMP_CALLS_PER_MINUTE = 10  # FMP free plan = 250/day, but no per-minute docs; be gentle

# --- API Base URLs ---
TD_BASE_URL = "https://api.twelvedata.com"
FMP_BASE_URL = "https://financialmodelingprep.com/api/v3"

# --- Vol Factor ETFs ---
VOL_LONG_ETF = "SPLV"
VOL_SHORT_ETF = "SPY"


# =============================================================================
# RATE LIMITER
# =============================================================================

class RateLimiter:
    """Simple rate limiter for API calls."""

    def __init__(self, calls_per_minute):
        self.delay = 60.0 / max(calls_per_minute, 1)
        self.last_call = 0
        self.total_calls = 0

    def wait(self):
        elapsed = time.time() - self.last_call
        if elapsed < self.delay:
            time.sleep(self.delay - elapsed)
        self.last_call = time.time()
        self.total_calls += 1


# =============================================================================
# HELPER: SAFE VALUE EXTRACTION
# =============================================================================

def to_float(val, default=np.nan):
    """Convert value to float, returning default on failure."""
    if val is None:
        return default
    try:
        return float(val)
    except (ValueError, TypeError):
        return default


# =============================================================================
# TWELVE DATA API CALL (for prices)
# =============================================================================

def td_api_call(endpoint, params, rate_limiter):
    """Make a rate-limited GET request to Twelve Data API."""
    rate_limiter.wait()
    params["apikey"] = TWELVE_DATA_API_KEY
    url = f"{TD_BASE_URL}/{endpoint}"

    try:
        resp = requests.get(url, params=params, timeout=30)

        if resp.status_code == 429:
            print(" [rate limited, waiting 60s]", end='')
            time.sleep(60)
            rate_limiter.wait()
            resp = requests.get(url, params=params, timeout=30)

        if resp.status_code != 200:
            return {"status": "error", "message": f"HTTP {resp.status_code}"}

        data = resp.json()
        if isinstance(data, dict) and data.get("status") == "error":
            return data

        return data

    except requests.exceptions.RequestException as e:
        return {"status": "error", "message": str(e)}


# =============================================================================
# FMP API CALL (for fundamentals)
# =============================================================================

def fmp_api_call(endpoint, rate_limiter, extra_params=None):
    """
    Make a rate-limited GET request to Financial Modeling Prep API.

    endpoint: e.g. "profile/AAPL" or "income-statement/AAPL"
    Returns: parsed JSON (list or dict) or None on failure.
    """
    rate_limiter.wait()
    url = f"{FMP_BASE_URL}/{endpoint}"
    params = {"apikey": FMP_API_KEY}
    if extra_params:
        params.update(extra_params)

    try:
        resp = requests.get(url, params=params, timeout=30)

        if resp.status_code == 429:
            print(" [FMP rate limited, waiting 30s]", end='')
            time.sleep(30)
            rate_limiter.wait()
            resp = requests.get(url, params=params, timeout=30)

        if resp.status_code != 200:
            return None

        data = resp.json()

        # FMP returns [] for invalid tickers, or {"Error Message": "..."} on errors
        if isinstance(data, dict) and "Error Message" in data:
            return None
        if isinstance(data, list) and len(data) == 0:
            return None

        return data

    except requests.exceptions.RequestException:
        return None


# =============================================================================
# STEP 1: LOAD TICKERS AND WEIGHTS FROM HOLDINGS FILE
# =============================================================================

def load_tickers_and_weights(holdings_file, portfolio_sheet, benchmark_sheet,
                             ticker_col, weight_col):
    """
    Dynamically read tickers and weights from the portfolio holdings Excel file.
    Returns: portfolio_weights (Series), benchmark_weights (Series), full_universe (list)
    """
    print("\n[1/8] Loading tickers from holdings file...")
    print(f"      File: {holdings_file}")

    try:
        port_df = pd.read_excel(holdings_file, sheet_name=portfolio_sheet)
        # port_weights = port_df.set_index(ticker_col)[weight_col]
        port_weights = port_df[port_df['Asset class'] == 'Equity'].set_index(ticker_col)[weight_col]
        port_weights = port_weights.groupby(level=0).sum()
        print(f"      Portfolio: {len(port_weights)} tickers from '{portfolio_sheet}'")
    except Exception as e:
        raise ValueError(f"Failed to read portfolio sheet '{portfolio_sheet}': {e}")

    try:
        bench_df = pd.read_excel(holdings_file, sheet_name=benchmark_sheet)
        bench_weights = bench_df.set_index(ticker_col)[weight_col]
        bench_weights = bench_weights.groupby(level=0).sum()
        print(f"      Benchmark: {len(bench_weights)} tickers from '{benchmark_sheet}'")
    except Exception as e:
        raise ValueError(f"Failed to read benchmark sheet '{benchmark_sheet}': {e}")

    # Full universe = union (Bug #3 fix)
    full_universe = sorted(set(port_weights.index.tolist() +
                               bench_weights.index.tolist()))
    print(f"      Full universe (union): {len(full_universe)} unique tickers")

    port_sum = port_weights.sum()
    bench_sum = bench_weights.sum()
    print(f"      Portfolio weight sum: {port_sum:.4f}")
    print(f"      Benchmark weight sum: {bench_sum:.4f}")
    if abs(port_sum - 1.0) > 0.05:
        print(f"      WARNING: Portfolio weights sum to {port_sum:.4f}, expected ~1.0")
    if abs(bench_sum - 1.0) > 0.05:
        print(f"      WARNING: Benchmark weights sum to {bench_sum:.4f}, expected ~1.0")

    return port_weights, bench_weights, full_universe


# =============================================================================
# STEP 2: DOWNLOAD MONTHLY PRICES (Twelve Data)
# =============================================================================

def download_monthly_prices(tickers, rate_limiter, ref_date, lookback_months):
    """Download monthly close prices from Twelve Data."""
    print(f"\n[2/8] Downloading monthly prices ({lookback_months} months) — Twelve Data...")

    ref = pd.Timestamp(ref_date)
    start = (ref - pd.DateOffset(months=lookback_months)).strftime('%Y-%m-%d')
    end = ref.strftime('%Y-%m-%d')
    print(f"      Period: {start} to {end}")

    all_series = {}
    errors = {}

    for i, ticker in enumerate(tickers, 1):
        print(f"\r      [{i}/{len(tickers)}] {ticker:<8s}", end='', flush=True)

        data = td_api_call("time_series", {
            "symbol": ticker, "interval": "1month",
            "start_date": start, "end_date": end, "order": "ASC"
        }, rate_limiter)

        if data is None or data.get("status") == "error":
            msg = data.get("message", "Unknown error") if data else "No response"
            errors[ticker] = f"monthly_prices: {msg}"
            continue

        values = data.get("values", [])
        if not values:
            errors[ticker] = "monthly_prices: no data returned"
            continue

        try:
            df = pd.DataFrame(values)
            df['datetime'] = pd.to_datetime(df['datetime'])
            df['close'] = df['close'].astype(float)
            all_series[ticker] = df.set_index('datetime')['close']
            all_series[ticker].name = ticker
        except Exception as e:
            errors[ticker] = f"monthly_prices: parse error - {e}"

    print(f"\n      Downloaded: {len(all_series)}/{len(tickers)} tickers")
    if errors:
        print(f"      Errors: {len(errors)} tickers (see Data_Log)")

    monthly_df = pd.DataFrame(all_series) if all_series else pd.DataFrame()
    if not monthly_df.empty:
        monthly_df.index.name = 'Date'
        monthly_df.sort_index(inplace=True)

    return monthly_df, errors


# =============================================================================
# STEP 3: DOWNLOAD DAILY PRICES (Twelve Data)
# =============================================================================

def download_daily_prices(tickers, rate_limiter, ref_date, lookback_days):
    """Download trailing daily close prices from Twelve Data."""
    print(f"\n[3/8] Downloading daily prices (trailing {lookback_days} days) — Twelve Data...")

    ref = pd.Timestamp(ref_date)
    start = (ref - pd.Timedelta(days=lookback_days)).strftime('%Y-%m-%d')
    end = ref.strftime('%Y-%m-%d')
    print(f"      Period: {start} to {end}")

    all_series = {}
    errors = {}

    for i, ticker in enumerate(tickers, 1):
        print(f"\r      [{i}/{len(tickers)}] {ticker:<8s}", end='', flush=True)

        data = td_api_call("time_series", {
            "symbol": ticker, "interval": "1day",
            "start_date": start, "end_date": end, "order": "ASC"
        }, rate_limiter)

        if data is None or data.get("status") == "error":
            msg = data.get("message", "Unknown error") if data else "No response"
            errors[ticker] = errors.get(ticker, "") + f"daily_prices: {msg}; "
            continue

        values = data.get("values", [])
        if not values:
            errors[ticker] = errors.get(ticker, "") + "daily_prices: no data; "
            continue

        try:
            df = pd.DataFrame(values)
            df['datetime'] = pd.to_datetime(df['datetime'])
            df['close'] = df['close'].astype(float)
            all_series[ticker] = df.set_index('datetime')['close']
            all_series[ticker].name = ticker
        except Exception as e:
            errors[ticker] = errors.get(ticker, "") + f"daily_prices: {e}; "

    print(f"\n      Downloaded: {len(all_series)}/{len(tickers)} tickers")

    daily_df = pd.DataFrame(all_series) if all_series else pd.DataFrame()
    if not daily_df.empty:
        daily_df.index.name = 'Date'
        daily_df.sort_index(inplace=True)

    return daily_df, errors


# =============================================================================
# STEP 4: DOWNLOAD FUNDAMENTAL DATA (FMP — FREE)
# =============================================================================

def download_fundamentals(tickers, rate_limiter):
    """
    Download fundamental data from Financial Modeling Prep (free API).

    3 endpoints per ticker:
      - /api/v3/profile/{ticker}           → mktCap, beta, price, volAvg
      - /api/v3/income-statement/{ticker}  → grossProfit, revenue, netIncome
      - /api/v3/balance-sheet-statement/{ticker} → totalAssets, equity, etc.

    Total FMP calls = 3 × N_tickers (69 for 23 tickers, well under 250/day)
    """
    print(f"\n[4/8] Downloading fundamentals — FMP (free)...")
    print(f"      Endpoints: profile, income-statement, balance-sheet-statement")
    print(f"      FMP API calls: {len(tickers) * 3} (free plan allows 250/day)")

    results = []
    errors = {}

    for i, ticker in enumerate(tickers, 1):
        print(f"\r      [{i}/{len(tickers)}] {ticker:<8s}", end='', flush=True)

        row = {"Ticker": ticker}

        # ---- Profile endpoint ----
        profile_data = fmp_api_call(f"profile/{ticker}", rate_limiter)

        if profile_data and isinstance(profile_data, list) and len(profile_data) > 0:
            p = profile_data[0]
            row["market_capitalization"] = to_float(p.get("mktCap"))
            row["beta"] = to_float(p.get("beta"))
            row["price"] = to_float(p.get("price"))
            row["avg_volume"] = to_float(p.get("volAvg"))
            row["shares_outstanding"] = to_float(
                p.get("mktCap", 0)) / max(to_float(p.get("price", 1)), 0.01)
            row["sector"] = p.get("sector", "")
            row["industry"] = p.get("industry", "")
            row["company_name"] = p.get("companyName", "")
        else:
            errors[ticker] = errors.get(ticker, "") + "profile: no data; "
            for fld in ["market_capitalization", "beta", "price", "avg_volume",
                        "shares_outstanding", "sector", "industry", "company_name"]:
                row[fld] = np.nan if fld not in ["sector", "industry", "company_name"] else ""

        # ---- Income Statement endpoint (annual, limit=1 for latest) ----
        inc_data = fmp_api_call(f"income-statement/{ticker}", rate_limiter,
                                {"period": "annual", "limit": "2"})

        if inc_data and isinstance(inc_data, list) and len(inc_data) > 0:
            latest = inc_data[0]
            row["income_fiscal_date"] = latest.get("date", "")
            row["gross_profit"] = to_float(latest.get("grossProfit"))
            row["total_revenue"] = to_float(latest.get("revenue"))
            row["net_income"] = to_float(latest.get("netIncome"))
            row["operating_income"] = to_float(latest.get("operatingIncome"))
            row["cost_of_revenue"] = to_float(latest.get("costOfRevenue"))
            row["operating_expenses"] = to_float(latest.get("operatingExpenses"))
        else:
            errors[ticker] = errors.get(ticker, "") + "income-statement: no data; "
            for fld in ["income_fiscal_date", "gross_profit", "total_revenue",
                        "net_income", "operating_income", "cost_of_revenue",
                        "operating_expenses"]:
                row[fld] = np.nan

        # ---- Balance Sheet endpoint (annual, limit=2 for current + prior year) ----
        bs_data = fmp_api_call(f"balance-sheet-statement/{ticker}", rate_limiter,
                               {"period": "annual", "limit": "2"})

        if bs_data and isinstance(bs_data, list) and len(bs_data) > 0:
            current = bs_data[0]
            row["bs_fiscal_date_current"] = current.get("date", "")
            row["total_assets_current"] = to_float(current.get("totalAssets"))
            row["total_liabilities"] = to_float(current.get("totalLiabilities"))
            row["total_stockholder_equity"] = to_float(
                current.get("totalStockholdersEquity",
                            current.get("totalEquity")))
            row["total_debt"] = to_float(current.get("totalDebt"))
            row["book_value_per_share"] = to_float(
                current.get("totalStockholdersEquity", 0)) / max(
                    row.get("shares_outstanding", 1), 1)

            # Prior year (for CMA / investment factor)
            if len(bs_data) > 1:
                prior = bs_data[1]
                row["bs_fiscal_date_prior"] = prior.get("date", "")
                row["total_assets_prior"] = to_float(prior.get("totalAssets"))
            else:
                row["bs_fiscal_date_prior"] = ""
                row["total_assets_prior"] = np.nan
                errors[ticker] = errors.get(ticker, "") + \
                    "balance-sheet: only 1 year (CMA not computable); "
        else:
            errors[ticker] = errors.get(ticker, "") + "balance-sheet: no data; "
            for fld in ["bs_fiscal_date_current", "total_assets_current",
                        "total_liabilities", "total_stockholder_equity",
                        "total_debt", "book_value_per_share",
                        "bs_fiscal_date_prior", "total_assets_prior"]:
                row[fld] = np.nan

        results.append(row)

    print(f"\n      Downloaded: {len(results)}/{len(tickers)} tickers")

    fundamentals_df = pd.DataFrame(results).set_index("Ticker")
    return fundamentals_df, errors


# =============================================================================
# STEP 5: LOAD FAMA-FRENCH FACTOR RETURNS (local files)
# =============================================================================

def load_fama_french_factors(ff5_file, momentum_file, ref_date, lookback_months):
    """
    Load FF5 + Momentum factor returns from local CSV.
    Expected: YYYYMM integer index, returns in percentage points.
    Returns: DataFrame with [Mkt-RF, SMB, HML, RMW, CMA, Mom, RF] in decimals.
    """
    print(f"\n[5/8] Loading Fama-French factor returns...")

    ref = pd.Timestamp(ref_date)
    start = ref - pd.DateOffset(months=lookback_months)

    print(f"      FF5 file: {ff5_file}")
    df_ff = pd.read_csv(ff5_file, index_col=0)
    df_ff.index = pd.to_datetime(df_ff.index.astype(str).str.strip(), format='%Y%m')

    ff5_cols = []
    for col in ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF']:
        if col in df_ff.columns:
            ff5_cols.append(col)
        else:
            print(f"      WARNING: '{col}' not found in FF5 file")

    factor_df = df_ff[ff5_cols].copy()

    # Momentum
    if 'Mom' in df_ff.columns:
        factor_df['Mom'] = df_ff['Mom']
        print(f"      Momentum found in FF5 file")
    elif momentum_file and momentum_file.strip():
        print(f"      Momentum file: {momentum_file}")
        df_mom = pd.read_csv(momentum_file, index_col=0)
        df_mom.index = pd.to_datetime(df_mom.index.astype(str).str.strip(), format='%Y%m')

        mom_col = None
        for candidate in ['Mom', 'MOM', 'WML', 'UMD', 'Momentum']:
            if candidate in df_mom.columns:
                mom_col = candidate
                break

        if mom_col:
            factor_df['Mom'] = df_mom[mom_col]
            print(f"      Momentum column '{mom_col}' loaded")
        else:
            print(f"      WARNING: No momentum column found. "
                  f"Available: {df_mom.columns.tolist()}")
    else:
        print(f"      WARNING: No momentum data. Set MOMENTUM_FILE path.")

    factor_df = factor_df / 100.0

    factor_df = factor_df[(factor_df.index >= start) & (factor_df.index <= ref)]
    factor_df.sort_index(inplace=True)
    factor_df.index.name = 'Date'

    print(f"      Factors: {factor_df.columns.tolist()}")
    print(f"      Period: {factor_df.index[0].strftime('%Y-%m')} to "
          f"{factor_df.index[-1].strftime('%Y-%m')}")
    print(f"      Observations: {len(factor_df)}")

    if len(factor_df) < lookback_months - 5:
        print(f"      WARNING: Only {len(factor_df)} months, expected ~{lookback_months}")

    return factor_df


# =============================================================================
# STEP 6: DOWNLOAD VOL FACTOR ETF PRICES (Twelve Data) & COMPUTE RETURNS
# =============================================================================

def download_vol_factor(rate_limiter, ref_date, lookback_months):
    """
    Download SPLV and SPY monthly prices from Twelve Data,
    compute vol factor = SPLV return - SPY return.
    """
    print(f"\n[6/8] Downloading vol factor ({VOL_LONG_ETF} - {VOL_SHORT_ETF}) — Twelve Data...")

    ref = pd.Timestamp(ref_date)
    start = (ref - pd.DateOffset(months=lookback_months + 2)).strftime('%Y-%m-%d')
    end = ref.strftime('%Y-%m-%d')

    etf_prices = {}
    for etf in [VOL_LONG_ETF, VOL_SHORT_ETF]:
        data = td_api_call("time_series", {
            "symbol": etf, "interval": "1month",
            "start_date": start, "end_date": end, "order": "ASC"
        }, rate_limiter)

        if data is None or data.get("status") == "error":
            msg = data.get("message", "Unknown") if data else "No response"
            print(f"      ERROR downloading {etf}: {msg}")
            return None

        values = data.get("values", [])
        if not values:
            print(f"      ERROR: No data for {etf}")
            return None

        df = pd.DataFrame(values)
        df['datetime'] = pd.to_datetime(df['datetime'])
        df['close'] = df['close'].astype(float)
        etf_prices[etf] = df.set_index('datetime')['close']

    splv_ret = etf_prices[VOL_LONG_ETF].pct_change().dropna()
    spy_ret = etf_prices[VOL_SHORT_ETF].pct_change().dropna()

    common_idx = splv_ret.index.intersection(spy_ret.index)
    vol_factor = splv_ret.loc[common_idx] - spy_ret.loc[common_idx]
    vol_factor.name = 'Vol'

    cutoff = ref - pd.DateOffset(months=lookback_months)
    vol_factor = vol_factor[vol_factor.index >= cutoff]

    print(f"      Vol factor: {len(vol_factor)} monthly observations")
    return vol_factor


# =============================================================================
# STEP 7: COMBINE ALL FACTOR RETURNS
# =============================================================================

def combine_factor_returns(ff_factors, vol_factor):
    """Merge Fama-French factors with the volatility factor."""
    print(f"\n[7/8] Combining factor returns...")

    combined = ff_factors.copy()
    if vol_factor is not None and len(vol_factor) > 0:
        combined['Vol'] = vol_factor
        combined.dropna(how='all', inplace=True)
    else:
        print(f"      WARNING: Vol factor not available. FF factors only.")

    print(f"      Combined: {combined.columns.tolist()}")
    print(f"      Common observations: {len(combined)}")
    return combined


# =============================================================================
# STEP 8: SAVE TO EXCEL
# =============================================================================

def save_to_excel(output_file, port_weights, bench_weights, monthly_prices,
                  daily_prices, fundamentals, factor_returns, data_log,
                  ref_date, lookback_months):
    """Save all data to a multi-sheet Excel workbook."""
    print(f"\n[8/8] Saving to Excel: {output_file}")

    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:

        # Sheet 1: Config
        config_data = {
            'Parameter': [
                'Reference_Date', 'Monthly_Lookback_Months',
                'Daily_Lookback_Days', 'Base_Currency',
                'Total_Portfolio_Tickers', 'Total_Benchmark_Tickers',
                'Total_Universe_Tickers', 'Factor_Count',
                'Factors', 'Monthly_Price_Observations',
                'FF_Factor_Observations',
                'Price_API', 'Fundamental_API',
                'Run_Timestamp'
            ],
            'Value': [
                ref_date, lookback_months,
                DAILY_LOOKBACK_CALENDAR_DAYS, 'USD',
                len(port_weights), len(bench_weights),
                len(set(port_weights.index.tolist() + bench_weights.index.tolist())),
                len(factor_returns.columns) if not factor_returns.empty else 0,
                ', '.join(factor_returns.columns.tolist()) if not factor_returns.empty else '',
                len(monthly_prices) if not monthly_prices.empty else 0,
                len(factor_returns) if not factor_returns.empty else 0,
                'Twelve Data', 'Financial Modeling Prep (free)',
                pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
            ]
        }
        pd.DataFrame(config_data).to_excel(writer, sheet_name='Config', index=False)

        # Sheet 2: Portfolio Weights
        pw = port_weights.reset_index()
        pw.columns = ['Ticker', 'Weight']
        pw.to_excel(writer, sheet_name='Portfolio_Weights', index=False)

        # Sheet 3: Benchmark Weights
        bw = bench_weights.reset_index()
        bw.columns = ['Ticker', 'Weight']
        bw.to_excel(writer, sheet_name='Benchmark_Weights', index=False)

        # Sheet 4: Monthly Prices
        if not monthly_prices.empty:
            monthly_prices.to_excel(writer, sheet_name='Monthly_Prices')

        # Sheet 5: Daily Prices
        if not daily_prices.empty:
            daily_prices.to_excel(writer, sheet_name='Daily_Prices')

        # Sheet 6: Fundamentals
        if not fundamentals.empty:
            fundamentals.to_excel(writer, sheet_name='Fundamentals')

        # Sheet 7: Factor Returns
        if not factor_returns.empty:
            factor_returns.to_excel(writer, sheet_name='Factor_Returns')

        # Sheet 8: Data Log
        if not data_log.empty:
            data_log.to_excel(writer, sheet_name='Data_Log', index=False)
        else:
            pd.DataFrame([{'Message': 'No issues encountered'}]).to_excel(
                writer, sheet_name='Data_Log', index=False)

    print(f"      Excel saved with 8 sheets")


# =============================================================================
# MAIN EXECUTION
# =============================================================================

def main():
    """Run complete data acquisition pipeline."""
    print("=" * 80)
    print("EQUITY TE ATTRIBUTION — MODULE 1: DATA ACQUISITION (v2 — Dual API)")
    print("=" * 80)
    print(f"\nReference Date:    {REFERENCE_DATE}")
    print(f"Monthly Lookback:  {MONTHLY_LOOKBACK_MONTHS} months")
    print(f"Price API:         Twelve Data ({TD_CALLS_PER_MINUTE} calls/min)")
    print(f"Fundamental API:   FMP free (250 calls/day)")

    td_limiter = RateLimiter(TD_CALLS_PER_MINUTE)
    fmp_limiter = RateLimiter(FMP_CALLS_PER_MINUTE)

    # ------------------------------------------------------------------
    # Step 1: Load tickers dynamically
    # ------------------------------------------------------------------
    port_weights, bench_weights, full_universe = load_tickers_and_weights(
        HOLDINGS_FILE, PORTFOLIO_SHEET, BENCHMARK_SHEET,
        TICKER_COLUMN, WEIGHT_COLUMN
    )

    # Price tickers = universe + vol factor ETFs
    price_tickers = sorted(set(full_universe + [VOL_LONG_ETF, VOL_SHORT_ETF]))

    # ------------------------------------------------------------------
    # Estimate API usage
    # ------------------------------------------------------------------
    n_price = len(price_tickers)
    n_fund = len(full_universe)

    td_calls = n_price * 2           # monthly + daily
    fmp_calls = n_fund * 3           # profile + income + balance sheet
    td_credits = n_price * 2         # 1 credit per price call
    td_minutes = td_calls / TD_CALLS_PER_MINUTE

    print(f"\n      --- API Usage Estimate ---")
    print(f"      Twelve Data:  {td_calls} calls, ~{td_credits} credits, "
          f"~{td_minutes:.0f} min")
    print(f"      FMP:          {fmp_calls} calls (free, 250/day limit)")
    print(f"      Total tickers for prices:       {n_price}")
    print(f"      Total tickers for fundamentals: {n_fund}")

    # ------------------------------------------------------------------
    # Step 2: Monthly prices (Twelve Data)
    # ------------------------------------------------------------------
    monthly_prices, monthly_errors = download_monthly_prices(
        price_tickers, td_limiter, REFERENCE_DATE, MONTHLY_LOOKBACK_MONTHS
    )

    # ------------------------------------------------------------------
    # Step 3: Daily prices (Twelve Data)
    # ------------------------------------------------------------------
    daily_prices, daily_errors = download_daily_prices(
        price_tickers, td_limiter, REFERENCE_DATE, DAILY_LOOKBACK_CALENDAR_DAYS
    )

    # ------------------------------------------------------------------
    # Step 4: Fundamentals (FMP — free)
    # ------------------------------------------------------------------
    fundamentals, fund_errors = download_fundamentals(
        full_universe, fmp_limiter
    )

    # ------------------------------------------------------------------
    # Step 5: Fama-French factors (local files)
    # ------------------------------------------------------------------
    ff_factors = load_fama_french_factors(
        FF5_FILE, MOMENTUM_FILE, REFERENCE_DATE, MONTHLY_LOOKBACK_MONTHS
    )

    # ------------------------------------------------------------------
    # Step 6: Vol factor (Twelve Data)
    # ------------------------------------------------------------------
    vol_factor = download_vol_factor(
        td_limiter, REFERENCE_DATE, MONTHLY_LOOKBACK_MONTHS
    )

    # ------------------------------------------------------------------
    # Step 7: Combine factor returns
    # ------------------------------------------------------------------
    factor_returns = combine_factor_returns(ff_factors, vol_factor)

    # ------------------------------------------------------------------
    # Build data quality log
    # ------------------------------------------------------------------
    log_rows = []
    for ticker in full_universe:
        row = {"Ticker": ticker}

        # Monthly prices
        if not monthly_prices.empty and ticker in monthly_prices.columns:
            valid = monthly_prices[ticker].dropna()
            row["Monthly_Months"] = len(valid)
            row["Monthly_First"] = valid.index[0].strftime('%Y-%m-%d') if len(valid) > 0 else ""
            row["Monthly_Last"] = valid.index[-1].strftime('%Y-%m-%d') if len(valid) > 0 else ""
        else:
            row["Monthly_Months"] = 0
            row["Monthly_First"] = ""
            row["Monthly_Last"] = ""

        # Daily prices
        if not daily_prices.empty and ticker in daily_prices.columns:
            row["Daily_Days"] = len(daily_prices[ticker].dropna())
        else:
            row["Daily_Days"] = 0

        # Fundamentals
        if not fundamentals.empty and ticker in fundamentals.index:
            f = fundamentals.loc[ticker]
            row["Has_MarketCap"] = "Yes" if pd.notna(f.get("market_capitalization")) else "No"
            row["Has_Beta"] = "Yes" if pd.notna(f.get("beta")) else "No"
            row["Has_GrossProfit"] = "Yes" if pd.notna(f.get("gross_profit")) else "No"
            row["Has_TotalAssets_Curr"] = "Yes" if pd.notna(f.get("total_assets_current")) else "No"
            row["Has_TotalAssets_Prior"] = "Yes" if pd.notna(f.get("total_assets_prior")) else "No"
            row["Has_Equity"] = "Yes" if pd.notna(f.get("total_stockholder_equity")) else "No"
        else:
            for fld in ["Has_MarketCap", "Has_Beta", "Has_GrossProfit",
                        "Has_TotalAssets_Curr", "Has_TotalAssets_Prior", "Has_Equity"]:
                row[fld] = "No"

        # Beta availability (pre-calculated from FMP, or estimable from prices)
        months = row.get("Monthly_Months", 0)
        has_fmp_beta = row.get("Has_Beta", "No") == "Yes"
        if has_fmp_beta:
            row["Beta_Source"] = "FMP (pre-calculated)"
        elif months >= 24:
            row["Beta_Source"] = f"Regression ({months} months)"
        elif months > 0:
            row["Beta_Source"] = f"Low confidence ({months} months)"
        else:
            row["Beta_Source"] = "Not available"

        # Aggregate errors
        all_errors = []
        if ticker in monthly_errors:
            all_errors.append(monthly_errors[ticker])
        if ticker in daily_errors:
            all_errors.append(daily_errors[ticker])
        if ticker in fund_errors:
            all_errors.append(fund_errors[ticker])
        row["Errors"] = " | ".join(all_errors) if all_errors else ""

        log_rows.append(row)

    data_log = pd.DataFrame(log_rows)

    # ------------------------------------------------------------------
    # Step 8: Save everything
    # ------------------------------------------------------------------
    save_to_excel(
        OUTPUT_FILE, port_weights, bench_weights,
        monthly_prices, daily_prices, fundamentals, factor_returns,
        data_log, REFERENCE_DATE, MONTHLY_LOOKBACK_MONTHS
    )

    # ------------------------------------------------------------------
    # Summary
    # ------------------------------------------------------------------
    print(f"\n{'='*80}")
    print("SUMMARY")
    print(f"{'='*80}")
    print(f"\n  Reference date:       {REFERENCE_DATE}")
    print(f"  Portfolio tickers:    {len(port_weights)}")
    print(f"  Benchmark tickers:    {len(bench_weights)}")
    print(f"  Full universe:        {len(full_universe)}")

    if not monthly_prices.empty:
        print(f"  Monthly prices:       {monthly_prices.shape[1]} tickers x "
              f"{monthly_prices.shape[0]} months")
    else:
        print(f"  Monthly prices:       NONE")

    if not daily_prices.empty:
        print(f"  Daily prices:         {daily_prices.shape[1]} tickers x "
              f"{daily_prices.shape[0]} days")
    else:
        print(f"  Daily prices:         NONE")

    if not fundamentals.empty:
        print(f"  Fundamentals:         {len(fundamentals)} tickers (FMP free)")
        has_beta = (fundamentals['beta'].notna()).sum() if 'beta' in fundamentals.columns else 0
        print(f"    Pre-calculated beta: {has_beta}/{len(fundamentals)} tickers")
    else:
        print(f"  Fundamentals:         NONE")

    if not factor_returns.empty:
        print(f"  Factor returns:       {len(factor_returns.columns)} factors x "
              f"{len(factor_returns)} months")
    else:
        print(f"  Factor returns:       NONE")

    # Data quality
    if not data_log.empty:
        threshold = MONTHLY_LOOKBACK_MONTHS - 5
        full = (data_log["Monthly_Months"] >= threshold).sum()
        partial = ((data_log["Monthly_Months"] > 0) &
                   (data_log["Monthly_Months"] < threshold)).sum()
        missing = (data_log["Monthly_Months"] == 0).sum()
        print(f"\n  Data quality:")
        print(f"    Full coverage (>={threshold} months):  {full}")
        print(f"    Partial coverage:              {partial}")
        print(f"    No price data:                 {missing}")

    print(f"\n  API calls made:")
    print(f"    Twelve Data: {td_limiter.total_calls}")
    print(f"    FMP:         {fmp_limiter.total_calls}")
    print(f"  Output: {OUTPUT_FILE}")
    print(f"\n{'='*80}")
    print("MODULE 1 COMPLETE — Ready for Module 2")
    print(f"{'='*80}")


# =============================================================================
# EXECUTE
# =============================================================================

if __name__ == "__main__":
    main()
